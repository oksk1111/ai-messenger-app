/**
 * ì±„íŒ… ì„œë¹„ìŠ¤ - ì‹¤ì‹œê°„ ì±„íŒ… ë° AI ë©”ì‹œì§€ ìƒì„±
 */

import { v4 as uuidv4 } from 'uuid';
import { format } from 'date-fns';

// ë©”ì‹œì§€ íƒ€ì… ìƒìˆ˜
export const MESSAGE_TYPES = {
  USER: 'user',
  AI: 'ai',
  SYSTEM: 'system'
};

// ë©”ì‹œì§€ ìƒíƒœ ìƒìˆ˜
export const MESSAGE_STATUS = {
  SENDING: 'sending',
  SENT: 'sent',
  DELIVERED: 'delivered',
  FAILED: 'failed'
};

/**
 * ì±„íŒ… ë©”ì‹œì§€ í´ë˜ìŠ¤
 */
export class ChatMessage {
  constructor(content, type = MESSAGE_TYPES.USER, sender = 'User') {
    this.id = uuidv4();
    this.content = content;
    this.type = type;
    this.sender = sender;
    this.timestamp = new Date();
    this.status = MESSAGE_STATUS.SENT;
    this.reactions = [];
    this.isEdited = false;
  }

  /**
   * ë©”ì‹œì§€ ì‹œê°„ í¬ë§·íŒ…
   */
  getFormattedTime() {
    return format(this.timestamp, 'HH:mm');
  }

  /**
   * ë©”ì‹œì§€ ë‚ ì§œ í¬ë§·íŒ…
   */
  getFormattedDate() {
    return format(this.timestamp, 'yyyy-MM-dd');
  }

  /**
   * ë©”ì‹œì§€ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
   */
  toJSON() {
    return {
      id: this.id,
      content: this.content,
      type: this.type,
      sender: this.sender,
      timestamp: this.timestamp.toISOString(),
      status: this.status,
      reactions: this.reactions,
      isEdited: this.isEdited
    };
  }

  /**
   * JSONì—ì„œ ë©”ì‹œì§€ ìƒì„±
   */
  static fromJSON(data) {
    const message = new ChatMessage(data.content, data.type, data.sender);
    message.id = data.id;
    message.timestamp = new Date(data.timestamp);
    message.status = data.status;
    message.reactions = data.reactions || [];
    message.isEdited = data.isEdited || false;
    return message;
  }
}

/**
 * ì±„íŒ…ë°© í´ë˜ìŠ¤
 */
export class ChatRoom {
  constructor(id, name = 'General Chat') {
    this.id = id;
    this.name = name;
    this.messages = [];
    this.participants = [];
    this.createdAt = new Date();
    this.isActive = true;
  }

  /**
   * ë©”ì‹œì§€ ì¶”ê°€
   */
  addMessage(message) {
    if (!(message instanceof ChatMessage)) {
      throw new Error('Message must be an instance of ChatMessage');
    }
    this.messages.push(message);
    return message;
  }

  /**
   * ë©”ì‹œì§€ ê²€ìƒ‰
   */
  findMessage(messageId) {
    return this.messages.find(msg => msg.id === messageId);
  }

  /**
   * ìµœê·¼ ë©”ì‹œì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
   */
  getRecentMessages(count = 50) {
    return this.messages.slice(-count);
  }

  /**
   * ë‚ ì§œë³„ ë©”ì‹œì§€ ê·¸ë£¹í™”
   */
  getMessagesByDate() {
    const grouped = {};
    this.messages.forEach(message => {
      const date = message.getFormattedDate();
      if (!grouped[date]) {
        grouped[date] = [];
      }
      grouped[date].push(message);
    });
    return grouped;
  }
}

/**
 * AI ë©”ì‹œì§€ ìƒì„± ì„œë¹„ìŠ¤
 */
export class AIMessageGenerator {
  constructor(config = {}) {
    this.apiType = config.apiType || 'mock'; // 'mock', 'ollama', 'groq', 'huggingface'
    this.apiUrl = config.apiUrl || '';
    this.apiKey = config.apiKey || '';
    this.model = config.model || 'llama2';
    this.isInitialized = false;
  }

  /**
   * AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
   */
  async initialize() {
    try {
      if (this.apiType === 'ollama') {
        // Ollama ì—°ê²° í™•ì¸
        const response = await fetch('http://localhost:11434/api/tags');
        if (!response.ok) {
          throw new Error('Ollama not running. Please start Ollama first.');
        }
        const data = await response.json();
        console.log('Available Ollama models:', data.models);
        
        // ì„ íƒí•œ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        const availableModels = data.models.map(m => m.name);
        if (availableModels.length === 0) {
          throw new Error('No models installed. Please install a model first: ollama pull llama2');
        }
        
        // ì„ íƒí•œ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
        if (!availableModels.some(name => name.includes(this.model))) {
          this.model = availableModels[0];
          console.log(`Model '${this.model}' not found, using '${this.model}' instead`);
        }
        
        this.isInitialized = true;
      } else if (this.apiType === 'groq') {
        if (!this.apiKey) {
          throw new Error('Groq API key is required');
        }
        this.isInitialized = true;
      } else if (this.apiType === 'mock') {
        // Mock APIëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
        this.isInitialized = true;
      }
      
      console.log(`AI service initialized: ${this.apiType}`);
      return true;
    } catch (error) {
      console.error('Failed to initialize AI service:', error);
      return false;
    }
  }

  /**
   * ë¬¸ë§¥ ê¸°ë°˜ ë‹¤ìŒ ë°œì–¸ ì œì•ˆ ìƒì„±
   */
  async generateContextSuggestion(messages, targetUser = null) {
    if (!this.isInitialized) {
      await this.initialize();
    }

    try {
      switch (this.apiType) {
        case 'ollama':
          return await this.generateSuggestionWithOllama(messages, targetUser);
        case 'groq':
          return await this.generateSuggestionWithGroq(messages, targetUser);
        case 'huggingface':
          return await this.generateSuggestionWithHuggingFace(messages, targetUser);
        case 'mock':
        default:
          return await this.generateMockSuggestion(messages, targetUser);
      }
    } catch (error) {
      console.error('AI suggestion generation failed:', error);
      return this.getFallbackSuggestion();
    }
  }

  /**
   * Ollamaë¡œ ë¬¸ë§¥ ì œì•ˆ ìƒì„±
   */
  async generateSuggestionWithOllama(messages, targetUser) {
    const prompt = this.buildSuggestionPrompt(messages, targetUser);
    
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: this.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.8,
          max_tokens: 50
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.status}`);
    }

    const data = await response.json();
    return this.cleanSuggestion(data.response);
  }

  /**
   * Groqë¡œ ë¬¸ë§¥ ì œì•ˆ ìƒì„±
   */
  async generateSuggestionWithGroq(messages, targetUser) {
    const chatMessages = this.buildSuggestionChatMessages(messages, targetUser);
    
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages: chatMessages,
        model: 'mixtral-8x7b-32768',
        temperature: 0.8,
        max_tokens: 50
      })
    });

    if (!response.ok) {
      throw new Error(`Groq API error: ${response.status}`);
    }

    const data = await response.json();
    return this.cleanSuggestion(data.choices?.[0]?.message?.content);
  }

  /**
   * HuggingFaceë¡œ ë¬¸ë§¥ ì œì•ˆ ìƒì„±
   */
  async generateSuggestionWithHuggingFace(messages, targetUser) {
    const prompt = this.buildSuggestionPrompt(messages, targetUser);
    
    const response = await fetch(
      `https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          inputs: prompt,
          parameters: {
            max_length: 50,
            temperature: 0.8
          }
        })
      }
    );

    if (!response.ok) {
      throw new Error(`HuggingFace API error: ${response.status}`);
    }

    const data = await response.json();
    return this.cleanSuggestion(data?.[0]?.generated_text);
  }

  /**
   * Mock ë¬¸ë§¥ ì œì•ˆ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
   */
  async generateMockSuggestion(messages, targetUser) {
    // ì‹¤ì œ ì‘ë‹µì²˜ëŸ¼ ë³´ì´ë„ë¡ ì§€ì—° ì¶”ê°€
    await new Promise(resolve => setTimeout(resolve, 500 + Math.random() * 1000));

    if (!messages || messages.length === 0) {
      return this.getRandomGreeting();
    }

    const lastMessage = messages[messages.length - 1];
    const lastContent = lastMessage.content.toLowerCase();

    // ë¬¸ë§¥ ê¸°ë°˜ ì œì•ˆ ìƒì„±
    if (lastContent.includes('ì•ˆë…•') || lastContent.includes('hi') || lastContent.includes('hello')) {
      const greetings = [
        "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”",
        "ë°˜ê°€ì›Œìš”! ì˜¤ëŠ˜ ì–´ë– ì„¸ìš”?",
        "ì•ˆë…•! ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ê³  ê³„ì‹ ê°€ìš”?",
        "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?"
      ];
      return greetings[Math.floor(Math.random() * greetings.length)];
    }

    if (lastContent.includes('?') || lastContent.includes('ì–´ë–»ê²Œ') || lastContent.includes('ì™œ')) {
      const questionResponses = [
        "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”!",
        "ê·¸ê±´ ì •ë§ ê¶ê¸ˆí•˜ë„¤ìš”",
        "ì €ë„ ê·¸ê²Œ ê¶ê¸ˆí•´ìš”",
        "í¥ë¯¸ë¡œìš´ ì ì´ë„¤ìš”"
      ];
      return questionResponses[Math.floor(Math.random() * questionResponses.length)];
    }

    if (lastContent.includes('ê³ ë§ˆ') || lastContent.includes('ê°ì‚¬')) {
      const thankResponses = [
        "ì²œë§Œì—ìš”!",
        "ë³„ ë§ì”€ì„ìš”",
        "ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ë‹¤í–‰ì´ì—ìš”",
        "ì–¸ì œë“ ì§€ ë§ì”€í•˜ì„¸ìš”"
      ];
      return thankResponses[Math.floor(Math.random() * thankResponses.length)];
    }

    if (lastContent.includes('ì¢‹ë‹¤') || lastContent.includes('ë©‹ì§€ë‹¤') || lastContent.includes('í›Œë¥­')) {
      const positiveResponses = [
        "ë§ì•„ìš”, ì •ë§ ì¢‹ë„¤ìš”!",
        "ì €ë„ ê·¸ë ‡ê²Œ ìƒê°í•´ìš”",
        "ì™„ì „ ë™ê°ì…ë‹ˆë‹¤",
        "ì •ë§ ë©‹ì§„ ê²ƒ ê°™ì•„ìš”"
      ];
      return positiveResponses[Math.floor(Math.random() * positiveResponses.length)];
    }

    if (lastContent.includes('í˜ë“¤ë‹¤') || lastContent.includes('ì–´ë µë‹¤') || lastContent.includes('ë¬¸ì œ')) {
      const supportResponses = [
        "í˜ë‚´ì„¸ìš”! ì˜ í•´ê²°ë  ê±°ì˜ˆìš”",
        "ì–´ë ¤ìš°ì‹œê² ì§€ë§Œ ì‘ì›í• ê²Œìš”",
        "ê´œì°®ì•„ì§ˆ ê±°ì˜ˆìš”",
        "í•¨ê»˜ í•´ê²°í•´ë´ìš”"
      ];
      return supportResponses[Math.floor(Math.random() * supportResponses.length)];
    }

    // ì¼ë°˜ì ì¸ ëŒ€í™” ì—°ê²° ì œì•ˆ
    const generalSuggestions = [
      "ê·¸ë ‡ê²Œ ìƒê°í•˜ì‹œëŠ”êµ°ìš”",
      "ë” ìì„¸íˆ ì–˜ê¸°í•´ì£¼ì„¸ìš”",
      "í¥ë¯¸ë¡­ë„¤ìš”!",
      "ì €ëŠ” ì–´ë–»ê²Œ ìƒê°í•˜ëƒë©´ìš”...",
      "ê·¸ëŸ° ê´€ì ë„ ìˆë„¤ìš”",
      "ì •ë§ìš”? ì‹ ê¸°í•˜ë„¤ìš”",
      "ì´í•´í•´ìš”",
      "ë§ëŠ” ë§ì”€ì´ì—ìš”",
      "ë‹¤ë¥¸ ì˜ê²¬ë„ ìˆì„ ê²ƒ ê°™ì•„ìš”",
      "ì¢‹ì€ ìƒê°ì´ì—ìš”!"
    ];

    return generalSuggestions[Math.floor(Math.random() * generalSuggestions.length)];
  }

  /**
   * ë¬¸ë§¥ ì œì•ˆìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
   */
  buildSuggestionPrompt(messages, targetUser) {
    let prompt = "You are helping to suggest the next natural response in a Korean conversation. ";
    prompt += "Based on the conversation context, suggest ONE short, natural Korean response (maximum 20 characters) that would fit well in this conversation flow.\n\n";
    prompt += "Recent conversation:\n";
    
    messages.slice(-5).forEach(msg => {
      prompt += `${msg.sender}: ${msg.content}\n`;
    });
    
    prompt += `\nSuggest a natural Korean response for the next speaker (keep it very short and conversational): `;
    return prompt;
  }

  /**
   * ë¬¸ë§¥ ì œì•ˆìš© ì±— ë©”ì‹œì§€ êµ¬ì„±
   */
  buildSuggestionChatMessages(messages, targetUser) {
    const systemMessage = {
      role: 'system',
      content: 'You are helping to suggest natural Korean conversation responses. Generate ONE very short, natural Korean response (maximum 20 characters) that would fit the conversation context. No explanations, just the suggested response.'
    };

    const contextMessage = {
      role: 'user',
      content: `Recent conversation:\n${messages.slice(-5).map(msg => `${msg.sender}: ${msg.content}`).join('\n')}\n\nSuggest a natural Korean response:`
    };

    return [systemMessage, contextMessage];
  }

  /**
   * ì œì•ˆ í…ìŠ¤íŠ¸ ì •ë¦¬ (ë”°ì˜´í‘œ, ì¤„ë°”ê¿ˆ ì œê±°)
   */
  cleanSuggestion(suggestion) {
    if (!suggestion) return this.getFallbackSuggestion();
    
    return suggestion
      .replace(/^["']|["']$/g, '') // ì‹œì‘/ë ë”°ì˜´í‘œ ì œê±°
      .replace(/\n/g, ' ') // ì¤„ë°”ê¿ˆì„ ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€ê²½
      .trim()
      .slice(0, 50); // ìµœëŒ€ 50ì ì œí•œ
  }

  /**
   * ëœë¤ ì¸ì‚¬ë§
   */
  getRandomGreeting() {
    const greetings = [
      "ì•ˆë…•í•˜ì„¸ìš”!",
      "ë°˜ê°€ì›Œìš”!",
      "ì¢‹ì€ í•˜ë£¨ì˜ˆìš”!",
      "ì•ˆë…•! ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
      "ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”",
      "ì˜¤ëŠ˜ ë‚ ì”¨ ì¢‹ë„¤ìš”!"
    ];
    return greetings[Math.floor(Math.random() * greetings.length)];
  }

  /**
   * í´ë°± ì œì•ˆ
   */
  getFallbackSuggestion() {
    const fallbacks = [
      "ê·¸ë ‡ë„¤ìš”",
      "ë§ì•„ìš”",
      "ì¢‹ì€ ìƒê°ì´ì—ìš”",
      "í¥ë¯¸ë¡­ë„¤ìš”",
      "ì´í•´í•´ìš”",
      "ì •ë§ìš”?"
    ];
    return fallbacks[Math.floor(Math.random() * fallbacks.length)];
  }

  /**
   * Ollamaë¡œ ì‘ë‹µ ìƒì„± (ë¡œì»¬, ë¬´ë£Œ)
   */
  async generateWithOllama(message, context) {
    const prompt = this.buildPrompt(message, context);
    
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: this.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.7,
          max_tokens: 150
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.status}`);
    }

    const data = await response.json();
    return data.response || this.getFallbackResponse();
  }

  /**
   * Groqë¡œ ì‘ë‹µ ìƒì„± (ë¹ ë¥¸ ë¬´ë£Œ í‹°ì–´)
   */
  async generateWithGroq(message, context) {
    const messages = this.buildChatMessages(message, context);
    
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages: messages,
        model: 'mixtral-8x7b-32768', // ë¹ ë¥´ê³  ì¢‹ì€ ë¬´ë£Œ ëª¨ë¸
        temperature: 0.7,
        max_tokens: 150
      })
    });

    if (!response.ok) {
      throw new Error(`Groq API error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices?.[0]?.message?.content || this.getFallbackResponse();
  }

  /**
   * HuggingFaceë¡œ ì‘ë‹µ ìƒì„±
   */
  async generateWithHuggingFace(message, context) {
    const prompt = this.buildPrompt(message, context);
    
    const response = await fetch(
      `https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          inputs: prompt,
          parameters: {
            max_length: 100,
            temperature: 0.7
          }
        })
      }
    );

    if (!response.ok) {
      throw new Error(`HuggingFace API error: ${response.status}`);
    }

    const data = await response.json();
    return data?.[0]?.generated_text || this.getFallbackResponse();
  }

  /**
   * Mock ì‘ë‹µ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
   */
  async generateMockResponse(message, context) {
    // ì‹¤ì œ ì‘ë‹µì²˜ëŸ¼ ë³´ì´ë„ë¡ ì§€ì—° ì¶”ê°€
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));

    const mockResponses = [
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
      "í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì´ë„¤ìš”. ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?",
      "ê·¸ëŸ° ê´€ì ì—ì„œ ìƒê°í•´ë³¸ ì ì´ ì—†ì—ˆëŠ”ë°ìš”. ì¢‹ì€ ì§€ì ì…ë‹ˆë‹¤!",
      "ì œê°€ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ìˆì„ê¹Œìš”?",
      "ì¢‹ì€ ìƒê°ì´ë„¤ìš”! ë‹¤ë¥¸ ì˜ê²¬ë„ ë“¤ì–´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.",
      "ì •ë§ ì¬ë¯¸ìˆëŠ” ì£¼ì œë„¤ìš”. ê³„ì† ì´ì•¼ê¸°í•´ë´ìš”!",
      "ì´í•´í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•´ë³¼ê¹Œìš”?",
      "ë§ìŠµë‹ˆë‹¤! ê·¸ë ‡ê²Œ ìƒê°í•˜ì‹œëŠ” ì´ìœ ê°€ ìˆë‚˜ìš”?",
      "ìƒˆë¡œìš´ ì •ë³´ë„¤ìš”. ë” ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.",
      "í›Œë¥­í•œ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤! ì–´ë–»ê²Œ ì‹¤í–‰í•˜ë©´ ì¢‹ì„ê¹Œìš”?"
    ];

    // ë©”ì‹œì§€ ë‚´ìš©ì— ë”°ë¥¸ ê°„ë‹¨í•œ ì‘ë‹µ ë¡œì§
    const lowerMessage = message.toLowerCase();
    
    if (lowerMessage.includes('ì•ˆë…•') || lowerMessage.includes('hi') || lowerMessage.includes('hello')) {
      return "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš”! ğŸ˜Š";
    }
    
    if (lowerMessage.includes('?') || lowerMessage.includes('ì§ˆë¬¸')) {
      return "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.";
    }
    
    if (lowerMessage.includes('ê³ ë§ˆ') || lowerMessage.includes('ê°ì‚¬')) {
      return "ì²œë§Œì—ìš”! ì–¸ì œë“ ì§€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š";
    }

    // ëœë¤ ì‘ë‹µ
    return mockResponses[Math.floor(Math.random() * mockResponses.length)];
  }

  /**
   * í”„ë¡¬í”„íŠ¸ êµ¬ì„±
   */
  buildPrompt(message, context) {
    let prompt = "You are a helpful and friendly AI assistant in a chat application. ";
    prompt += "Respond naturally and conversationally in Korean. Keep responses concise and engaging.\n\n";
    
    if (context.length > 0) {
      prompt += "Previous conversation:\n";
      context.slice(-3).forEach(msg => {
        prompt += `${msg.sender}: ${msg.content}\n`;
      });
    }
    
    prompt += `User: ${message}\nAI:`;
    return prompt;
  }

  /**
   * ì±— ë©”ì‹œì§€ í˜•ì‹ êµ¬ì„±
   */
  buildChatMessages(message, context) {
    const messages = [
      {
        role: 'system',
        content: 'You are a helpful and friendly AI assistant. Respond naturally in Korean, keeping responses concise and engaging.'
      }
    ];

    // ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    context.slice(-5).forEach(msg => {
      messages.push({
        role: msg.type === MESSAGE_TYPES.USER ? 'user' : 'assistant',
        content: msg.content
      });
    });

    // í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    messages.push({
      role: 'user',
      content: message
    });

    return messages;
  }

  /**
   * í´ë°± ì‘ë‹µ
   */
  getFallbackResponse() {
    const fallbacks = [
      "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
      "ì ì‹œ ë¬¸ì œê°€ ìˆì—ˆë„¤ìš”. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê² ì–´ìš”?",
      "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¡°ê¸ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    ];
    return fallbacks[Math.floor(Math.random() * fallbacks.length)];
  }

  /**
   * Ollama ìƒíƒœ ë° ëª¨ë¸ ëª©ë¡ í™•ì¸
   */
  static async getOllamaStatus() {
    try {
      const response = await fetch('http://localhost:11434/api/tags');
      if (!response.ok) {
        return { 
          isRunning: false, 
          models: [], 
          error: 'Ollama server is not running' 
        };
      }
      
      const data = await response.json();
      return {
        isRunning: true,
        models: data.models || [],
        error: null
      };
    } catch (error) {
      return {
        isRunning: false,
        models: [],
        error: error.message
      };
    }
  }

  /**
   * íŠ¹ì • ëª¨ë¸ í…ŒìŠ¤íŠ¸
   */
  static async testOllamaModel(modelName) {
    try {
      const response = await fetch('http://localhost:11434/api/generate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: modelName,
          prompt: 'Hello, respond with just "Hi there!"',
          stream: false,
          options: {
            temperature: 0.1,
            max_tokens: 10
          }
        })
      });

      if (!response.ok) {
        throw new Error(`Model test failed: ${response.status}`);
      }

      const data = await response.json();
      return {
        success: true,
        response: data.response,
        model: modelName
      };
    } catch (error) {
      return {
        success: false,
        error: error.message,
        model: modelName
      };
    }
  }
}

/**
 * ì±„íŒ… ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤
 */
export class ChatService {
  constructor() {
    this.rooms = new Map();
    this.aiGenerator = new AIMessageGenerator({ apiType: 'mock' }); // ê¸°ë³¸ê°’ì€ mock
    this.currentRoomId = null;
    this.messageListeners = [];
    this.isAIEnabled = true;
  }

  /**
   * AI ì„œë¹„ìŠ¤ ì„¤ì •
   */
  configureAI(config) {
    this.aiGenerator = new AIMessageGenerator(config);
    return this.aiGenerator.initialize();
  }

  /**
   * ì±„íŒ…ë°© ìƒì„±
   */
  createRoom(name = 'General Chat') {
    const roomId = uuidv4();
    const room = new ChatRoom(roomId, name);
    this.rooms.set(roomId, room);
    
    // í™˜ì˜ ë©”ì‹œì§€ ì¶”ê°€
    const welcomeMessage = new ChatMessage(
      `${name} ì±„íŒ…ë°©ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!`,
      MESSAGE_TYPES.SYSTEM,
      'System'
    );
    room.addMessage(welcomeMessage);
    
    return room;
  }

  /**
   * ì±„íŒ…ë°© ê°€ì ¸ì˜¤ê¸°
   */
  getRoom(roomId) {
    return this.rooms.get(roomId);
  }

  /**
   * í˜„ì¬ ì±„íŒ…ë°© ì„¤ì •
   */
  setCurrentRoom(roomId) {
    if (this.rooms.has(roomId)) {
      this.currentRoomId = roomId;
      return this.rooms.get(roomId);
    }
    return null;
  }

  /**
   * ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡ (AI ì‘ë‹µ ì—†ì´)
   */
  async sendUserMessage(content, sender = 'User') {
    if (!this.currentRoomId) {
      throw new Error('No active chat room');
    }

    const room = this.rooms.get(this.currentRoomId);
    const message = new ChatMessage(content, MESSAGE_TYPES.USER, sender);
    
    // ë©”ì‹œì§€ë¥¼ ë°©ì— ì¶”ê°€
    room.addMessage(message);
    
    // ë¦¬ìŠ¤ë„ˆë“¤ì—ê²Œ ìƒˆ ë©”ì‹œì§€ ì•Œë¦¼
    this.notifyMessageListeners(message, room);

    return message;
  }

  /**
   * ë¬¸ë§¥ ê¸°ë°˜ ë‹¤ìŒ ë°œì–¸ ì œì•ˆ ìƒì„±
   */
  async generateContextSuggestion(recentMessages) {
    if (!this.isAIEnabled) {
      return '';
    }

    try {
      return await this.aiGenerator.generateContextSuggestion(recentMessages);
    } catch (error) {
      console.error('Failed to generate context suggestion:', error);
      return '';
    }
  }

  /**
   * ë©”ì‹œì§€ ì „ì†¡ (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„± ìœ ì§€)
   */
  async sendMessage(content, type = MESSAGE_TYPES.USER, sender = 'User') {
    return await this.sendUserMessage(content, sender);
  }

  /**
   * ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
   */
  onMessage(callback) {
    this.messageListeners.push(callback);
    
    // ë¦¬ìŠ¤ë„ˆ ì œê±° í•¨ìˆ˜ ë°˜í™˜
    return () => {
      const index = this.messageListeners.indexOf(callback);
      if (index > -1) {
        this.messageListeners.splice(index, 1);
      }
    };
  }

  /**
   * ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆë“¤ì—ê²Œ ì•Œë¦¼
   */
  notifyMessageListeners(message, room) {
    this.messageListeners.forEach(callback => {
      try {
        callback(message, room);
      } catch (error) {
        console.error('Message listener error:', error);
      }
    });
  }

  /**
   * AI í† ê¸€
   */
  toggleAI() {
    this.isAIEnabled = !this.isAIEnabled;
    return this.isAIEnabled;
  }

  /**
   * ì±„íŒ… ë°ì´í„° ì €ì¥ (ë¡œì»¬ìŠ¤í† ë¦¬ì§€)
   */
  saveToLocalStorage() {
    const data = {
      rooms: Array.from(this.rooms.entries()).map(([id, room]) => [
        id, 
        {
          ...room,
          messages: room.messages.map(msg => msg.toJSON())
        }
      ]),
      currentRoomId: this.currentRoomId,
      isAIEnabled: this.isAIEnabled
    };
    
    localStorage.setItem('ai_messenger_chat_data', JSON.stringify(data));
  }

  /**
   * ì±„íŒ… ë°ì´í„° ë¡œë“œ (ë¡œì»¬ìŠ¤í† ë¦¬ì§€)
   */
  loadFromLocalStorage() {
    try {
      const data = localStorage.getItem('ai_messenger_chat_data');
      if (!data) return false;

      const parsed = JSON.parse(data);
      
      // ë°© ë°ì´í„° ë³µì›
      this.rooms.clear();
      parsed.rooms.forEach(([id, roomData]) => {
        const room = new ChatRoom(id, roomData.name);
        room.messages = roomData.messages.map(msgData => ChatMessage.fromJSON(msgData));
        room.participants = roomData.participants || [];
        room.createdAt = new Date(roomData.createdAt);
        room.isActive = roomData.isActive;
        
        this.rooms.set(id, room);
      });

      this.currentRoomId = parsed.currentRoomId;
      this.isAIEnabled = parsed.isAIEnabled !== false;
      
      return true;
    } catch (error) {
      console.error('Failed to load chat data:', error);
      return false;
    }
  }
}

// ì „ì—­ ì±„íŒ… ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
export const globalChatService = new ChatService();
